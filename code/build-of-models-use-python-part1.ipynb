{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import math\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def red_csv():\n",
    "    # read dataframe\n",
    "    train = pd.read_csv(\"C:\\\\Users\\\\King\\\\Desktop\\\\project_\\\\train.txt\", header=None, sep=\" \")\n",
    "    #read all columns and rows\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete \":\" of data\n",
    "def extract_query(qstr):\n",
    "    return qstr[4:]\n",
    "def extract_features(features):\n",
    "    return features.split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preparing(df):\n",
    "    df[1] = df[1].apply(extract_query)\n",
    "    df[df.columns[2:66]] = df[df.columns[2:66]].applymap(extract_features)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call of  function\n",
    "train_df = df_preparing(red_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the four ranks\n",
    "# belonging to the same person into 1d \n",
    "# matrix and group all persons \n",
    "# together in a two-dimensional matrix  \n",
    "def convert(lst, var_lst): \n",
    "    it = iter(lst) \n",
    "    return [list(islice(it, i)) for i in var_lst] \n",
    "def build_train_y():\n",
    "    # Take col 0 \n",
    "    train_y = train_df[train_df.columns[0]]\n",
    "    # biuld 2d Array\n",
    "    var_lst2 = [4 for i in range(0,204)] \n",
    "    train_y=convert(train_y[:816], var_lst2)\n",
    "    return train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and testing\n",
    "def Divide_data():\n",
    "    # Take rows from 0 to 816\n",
    "    train_x=train_df[train_df.columns[2:]][:816:4]\n",
    "    # Take rows from 816 to end\n",
    "    test=train_df[train_df.columns[2:]][816::4]\n",
    "    return train_x,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_modele_one():\n",
    "    train_x,test=Divide_data()\n",
    "    train_y=build_train_y()\n",
    "    model_one = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n",
    "    # Data training\n",
    "    model_one.fit(train_x, train_y)\n",
    "    # Test model\n",
    "    prediction_one = model_one.predict(test)\n",
    "    # checked of score\n",
    "    model_one.score(train_x, train_y)\n",
    "    # print prediction\n",
    "    return prediction_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_modele_two():\n",
    "    train_x,test=Divide_data()\n",
    "    train_y=bild_train_y()\n",
    "    model_two = MultiOutputRegressor(Ridge(random_state=0))\n",
    "    # Data training\n",
    "    model_two.fit(train_x, train_y)\n",
    "    # Test model\n",
    "    prediction_two = model_two.predict(test)\n",
    "    # checked of score\n",
    "    model_two.score(train_x, train_y)\n",
    "    # print prediction\n",
    "    return prediction_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train file txt\n",
    "def read_train():\n",
    "    training_data = xgb.DMatrix(r\"C:\\\\Users\\\\King\\\\Desktop\\project_\\\\train00.txt\")\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test file txt\n",
    "def read_test():\n",
    "    testing_data = xgb.DMatrix(r\"C:\\\\Users\\\\King\\\\Desktop\\project_\\\\train01.txt\")\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list-wise\n",
    "def build_model_three(training_data,testing_data):\n",
    "    ltr_lambdamart_param = [('objective','rank:ndcg'),('max_depth',3), ('eta',0.1), ('seed',404)]\n",
    "    #build model\n",
    "    lambdamart_model = xgb.train(ltr_lambdamart_param, training_data)\n",
    "    # test model\n",
    "    pred_lambdamart = lambdamart_model.predict(testing_data)\n",
    "    return pred_lambdamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambdarank (pairwise LTR)\n",
    "def build_model_four(training_data,testing_data):\n",
    "    ltr_lambdarank_param = [('objective','rank:pairwise'),('max_depth',3), ('eta',0.1), ('seed',404)]\n",
    "    lambdarank_model = xgb.train(ltr_lambdarank_param, training_data)\n",
    "    # test model\n",
    "    pred_lambdarank = lambdarank_model.predict(testing_data)\n",
    "    return pred_lambdarank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate DCG\n",
    "def DCG(rank,size):\n",
    "    dcg=0\n",
    "    sum=2\n",
    "    for n in range(size,len(rank)):\n",
    "        if n==size:\n",
    "            dcg = dcg+rank[size]\n",
    "        else:\n",
    "            dcg=dcg+(rank[n]/math.log(sum,2))\n",
    "            sum=sum+1\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculate average NDCG for all quesries in the test file\n",
    "def calculate_NDCG():\n",
    "    training_data=read_train()\n",
    "    testing_data=read_test()\n",
    "    \n",
    "    prediction_one=build_modele_one()\n",
    "    prediction_tow=build_modele_two()\n",
    "    pred_lambdamart=build_model_three(training_data,testing_data)\n",
    "    pred_lambdarank=build_model_four(training_data,testing_data)\n",
    "    \n",
    "    #calculate NDCG to all modeles\n",
    "    ndcg_model_one=DCG(prediction_one.round().flatten().astype(int),0)/DCG(train_df[0][400:],400)\n",
    "    ndcg_model_two=DCG(prediction_tow.round().flatten().astype(int),0)/DCG(train_df[0][400:],400)\n",
    "    ndcg_model_three=DCG(pred_lambdamart,0)/DCG(train_df[0][400:],400)\n",
    "    ndcg_model_four=DCG(pred_lambdarank,0)/DCG(train_df[0][400:],400)\n",
    "    \n",
    "    return ndcg_model_one,ndcg_model_two,ndcg_model_three,ndcg_model_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ndcg_model_one,ndcg_model_two,ndcg_model_three,ndcg_model_four=calculate_NDCG()\n",
    "    return print(ndcg_model_one,ndcg_model_two,ndcg_model_three,ndcg_model_four)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9574466058662415 0.967944510454367 0.12269779561502207 0.12269779561502207\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
